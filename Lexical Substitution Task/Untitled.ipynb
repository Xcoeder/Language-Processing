{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('interruption.n.02.break'),\n",
       " Lemma('break.n.02.break'),\n",
       " Lemma('fault.n.04.break'),\n",
       " Lemma('rupture.n.02.break'),\n",
       " Lemma('respite.n.02.break'),\n",
       " Lemma('breakage.n.03.break'),\n",
       " Lemma('pause.n.01.break'),\n",
       " Lemma('fracture.n.01.break'),\n",
       " Lemma('break.n.09.break'),\n",
       " Lemma('break.n.10.break'),\n",
       " Lemma('break.n.11.break'),\n",
       " Lemma('break.n.12.break'),\n",
       " Lemma('break.n.13.break'),\n",
       " Lemma('break.n.14.break'),\n",
       " Lemma('open_frame.n.01.break'),\n",
       " Lemma('break.n.16.break')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmas('break',pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=wn.lemmas('break',pos='n')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('break.n.02')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1=l1.synset()\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.lemmas()[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an unexpected piece of good luck he finally got his big break'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=s1.definition()\n",
    "b=s1.examples()\n",
    "a+\" \"+b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s): \n",
    "    \"\"\"\n",
    "    a naive tokenizer that splits on punctuation and whitespaces.  \n",
    "    \"\"\"\n",
    "    s = \"\".join(\" \" if x in string.punctuation else x for x in s.lower())    \n",
    "    return s.split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(lemma, pos) :#-> List[str]:\n",
    "    ls=wn.lemmas(lemma,pos)\n",
    "    result=[]\n",
    "    for l in ls:\n",
    "        for m in l.synset().lemmas():\n",
    "            if m.name()!=lemma:\n",
    "                result.append(str(m.name()))\n",
    "    return list(set(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dull',\n",
       " 'dumb',\n",
       " 'wearisome',\n",
       " 'dim',\n",
       " 'obtuse',\n",
       " 'deadening',\n",
       " 'ho-hum',\n",
       " 'sluggish',\n",
       " 'boring',\n",
       " 'dense',\n",
       " 'tiresome',\n",
       " 'tedious',\n",
       " 'irksome']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_candidates('slow','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wn_frequency_predictor(lem,pos):# : Context)# -> str:\n",
    "    lem=context.lemma\n",
    "    pos=context.pos\n",
    "    \n",
    "    ls=wn.lemmas(lem,pos)\n",
    "    result=dict()\n",
    "    for l in ls:\n",
    "        for m in l.synset().lemmas():\n",
    "            if m.name()!=lem:\n",
    "                if m.name() not in result.keys():\n",
    "                    result[m.name()]=l.count()\n",
    "                else:\n",
    "                    result[m.name()]+=l.count()\n",
    "                \n",
    "    \n",
    "    return [k for k,v in result.items() if v == max(result.values())][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lswn_frequency_predictor('slow','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense', 'dim', 'dull', 'dumb', 'obtuse']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('boring.s.01.boring'),\n",
       " Lemma('boring.s.01.deadening'),\n",
       " Lemma('boring.s.01.dull'),\n",
       " Lemma('boring.s.01.ho-hum'),\n",
       " Lemma('boring.s.01.irksome'),\n",
       " Lemma('boring.s.01.slow'),\n",
       " Lemma('boring.s.01.tedious'),\n",
       " Lemma('boring.s.01.tiresome'),\n",
       " Lemma('boring.s.01.wearisome')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[4].synset().lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ls=wn.lemmas('slow',pos='a')\n",
    "result=dict()\n",
    "for l in ls:\n",
    "    print(l.count())\n",
    "    for m in l.synset().lemmas():\n",
    "        if m.name()!='slow':\n",
    "            if m.name() not in result.keys():\n",
    "                result[m.name()]=l.count()\n",
    "            else:\n",
    "                result[m.name()]+=l.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "b=[3,4,5]\n",
    "# c=a.extend(b)\n",
    "# a.remove(1)\n",
    "#b\n",
    "[i for i in b if not i in a and i !=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wn_simple_lesk_predictor(lemma,pos,left_context,right_context):# : Context) -> str:\n",
    "    lemma=context.lemma\n",
    "    pos=context.pos\n",
    "    ls=wn.lemmas(lemma,pos)\n",
    "    left_context = context.left_context\n",
    "    right_context =context.right_context\n",
    "    left_context.extend(right_context)\n",
    "    stop_words = stopwords.words('english')\n",
    "    left_context=[i for i in left_context if not i in stop_words]\n",
    "    overlap=dict()\n",
    "    syn_freq=dict()\n",
    "    for l in ls:\n",
    "        syn_freq[l.synset()]=l.count()\n",
    "        # construct definition\n",
    "        s=l.synset()\n",
    "        defi=s.definition()\n",
    "        ex=s.examples()\n",
    "        for e in ex:\n",
    "            defi=defi+\" \"+e\n",
    "        hyper=s.hypernyms()\n",
    "        for h in hyper:\n",
    "            defi=defi+\" \"+h.definition()\n",
    "            for e in h.examples:\n",
    "                defi=defi+\" \"+e\n",
    "        # compute overlap\n",
    "        defi=tokenize(defi)\n",
    "        defi=[i for i in defi if not i in stop_words]\n",
    "        count=0\n",
    "        for d in defi:\n",
    "            if d in left_context:\n",
    "                count+=1\n",
    "        overlap[s]=count\n",
    "        \n",
    "    #choose synset\n",
    "    re=[k for k,v in overlap.items() if v == max(overlap.values()) and v!=0]\n",
    "    if len(re)==0 or len(re)!=1:\n",
    "        syn=[k for k,v in syn_freq.items()]\n",
    "    else:\n",
    "        syn=re\n",
    "    \n",
    "    #choose lexeme\n",
    "    lexme=dict()\n",
    "    for s in syn:\n",
    "        for l in s.lemmas():\n",
    "            lexme[l]=l.count()\n",
    "            \n",
    "    result=[k for k,v in lexme.items() if k.name()!=lemma]\n",
    "    result=[k for k,v in lexme.items() if v == max(lexme.values())]\n",
    "    result=result[0].name()\n",
    "    \n",
    "    return result\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_freq=wn_simple_lesk_predictor('tight','a',['Anyway', ',', 'my', 'pants', 'are', 'getting'],['every','day','.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-00ef1e54ce83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msyn_freq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyn_freq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "[k for k,v in syn_freq.items() if v == max(syn_freq.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'taut'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nearest(self,context : Context) -> str:\n",
    "    lemma=context.lemma\n",
    "    pos=context.pos\n",
    "    synonyms=get_candidates(lemma, pos)\n",
    "    result=dict()\n",
    "    for w in synonyms:\n",
    "        result[w]=self.model.similarity(lemma,w)\n",
    "    result=[k for k,v in result.items() if v == max(result.values())][0]\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "numpy>=1.17 is required for a normal functioning of this module, but found numpy==1.16.2.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-428191b397a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#import tensorflow as tf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m from .utils import (\n\u001b[0;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# not required, check version only if installed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mrequire_version_core\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"can't find {pkg} in {deps.keys()}, check dependency_versions_table.py\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\utils\\versions.py\u001b[0m in \u001b[0;36mrequire_version_core\u001b[1;34m(requirement)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;34m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mhint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Try: pip install transformers -U or pip install -e '.[dev]' if you're working with git main\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\utils\\versions.py\u001b[0m in \u001b[0;36mrequire_version\u001b[1;34m(requirement, hint)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwanted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0m_compare_versions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_ver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwant_ver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequirement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpkg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\utils\\versions.py\u001b[0m in \u001b[0;36m_compare_versions\u001b[1;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgot_ver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwant_ver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         raise ImportError(\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;34mf\"{requirement} is required for a normal functioning of this module, but found {pkg}=={got_ver}.{hint}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         )\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy>=1.17 is required for a normal functioning of this module, but found numpy==1.16.2.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (4.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\xxx\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: importlib-metadata in d:\\anaconda\\lib\\site-packages (from transformers) (6.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in d:\\anaconda\\lib\\site-packages (from transformers) (0.13.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers) (5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.1)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda\\lib\\site-packages (from importlib-metadata->transformers) (3.15.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anyway, my pants are getting [MASK] every day.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "a=['Anyway', ',', 'my', 'pants', 'are', 'getting']\n",
    "a.append('[MASK]')\n",
    "a.extend(['every','day','.'])\n",
    "s=\"\".join([x if x in string.punctuation else \" \"+x for x in a])\n",
    "s[1:]\n",
    "\n",
    "\n",
    ">>> \n",
    ">>> \n",
    ">>> predictions = outputs[0]\n",
    ">>>  # Sort in increasing order\n",
    ">>> tokenizer.convert_ids_to_tokens(best_words[:10])\n",
    "['stolen', 'wasted', 'worthless', 'dirty', 'yours', 'lost', 'money', 'worth', 'good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertPredictor(object):\n",
    "\n",
    "    def __init__(self): \n",
    "        self.tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.model = transformers.TFDistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    def predict(self, context : Context) -> str:\n",
    "        lemma=context.lemma\n",
    "        pos=context.pos\n",
    "        left_context=context.left_context\n",
    "        right_context=context.right_context\n",
    "        #obtain synonyms\n",
    "        synonyms=get_candidates(lemma,pos)\n",
    "        \n",
    "        #step2\n",
    "        left_context.append('[MASK]')\n",
    "        left_context.extend(right_context)\n",
    "        s=\"\".join([x if x in string.punctuation else \" \"+x for x in left_context])\n",
    "        s=s[1:]\n",
    "        input_toks = self.tokenizer.encode(s)\n",
    "        input_mat = np.array(input_toks).reshape((1,-1))\n",
    "        mask_id=self.tokenizer.convert_ids_to_tokens(input_toks).index('[MASK]')\n",
    "        \n",
    "        \n",
    "        #step3\n",
    "        outputs = self.model.predict(input_mat)\n",
    "        \n",
    "        #step4\n",
    "        predictions=outputs[0]\n",
    "        best_words = np.argsort(predictions[0][mask_id])[::-1]\n",
    "        words=self.tokenizer.convert_ids_to_tokens(best_words)\n",
    "        \n",
    "        result=dict()\n",
    "        for w in synonyms:\n",
    "            result[w]=words.index(w)\n",
    "        \n",
    "        best=[k for k,v in result.items() if v == min(result.values())][0]\n",
    "        return best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "numpy>=1.17 is required for a normal functioning of this module, but found numpy==1.16.2.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-279c49635b32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m from .utils import (\n\u001b[0;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# not required, check version only if installed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mrequire_version_core\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"can't find {pkg} in {deps.keys()}, check dependency_versions_table.py\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\utils\\versions.py\u001b[0m in \u001b[0;36mrequire_version_core\u001b[1;34m(requirement)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;34m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mhint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Try: pip install transformers -U or pip install -e '.[dev]' if you're working with git main\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\utils\\versions.py\u001b[0m in \u001b[0;36mrequire_version\u001b[1;34m(requirement, hint)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwanted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0m_compare_versions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_ver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwant_ver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequirement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpkg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\transformers\\utils\\versions.py\u001b[0m in \u001b[0;36m_compare_versions\u001b[1;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgot_ver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwant_ver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         raise ImportError(\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;34mf\"{requirement} is required for a normal functioning of this module, but found {pkg}=={got_ver}.{hint}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         )\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy>=1.17 is required for a normal functioning of this module, but found numpy==1.16.2.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main"
     ]
    }
   ],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Compiled extensions are unavailable. If you've installed from a package, ask the package maintainer to include compiled extensions. If you're building Gensim from source yourself, install Cython and a C compiler, and then run `python setup.py build_ext --inplace` to retry. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    263\u001b[0m     )\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfasttext_corpusfile\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_epoch_sg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_epoch_cbow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: 找不到指定的模块。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e70e92d32c6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\gensim\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\gensim\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0matmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAuthorTopicModel\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mldaseqmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLdaSeqModel\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfasttext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFastText\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtranslation_matrix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTranslationMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBackMappingTranslationMatrix\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mensemblelda\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEnsembleLda\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfasttext_corpusfile\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_epoch_sg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_epoch_cbow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNO_CYTHON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Compiled extensions are unavailable. If you've installed from a package, ask the package maintainer to include compiled extensions. If you're building Gensim from source yourself, install Cython and a C compiler, and then run `python setup.py build_ext --inplace` to retry. "
     ]
    }
   ],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma='slow'\n",
    "pos='a'\n",
    "synonyms=get_candidates(lemma, pos)\n",
    "result=dict()\n",
    "for w in synonyms:\n",
    "    result[w]=1\n",
    "result=[k for k,v in result.items() if v == max(result.values())][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boring'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
